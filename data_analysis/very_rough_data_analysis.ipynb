{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9113b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3654b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6475\n",
      "970\n",
      "1691\n"
     ]
    }
   ],
   "source": [
    "FILEPATH_BASE = 'QNLI/QNLI-Stress Test/'\n",
    "\n",
    "FILEPATH_TRAIN = 'QNLI-Stress Test_train.json'\n",
    "FILEPATH_TEST = 'QNLI-Stress Test_test.json'\n",
    "FILEPATH_DEV = 'QNLI-Stress Test_dev.json'\n",
    "\n",
    "with open(FILEPATH_BASE + FILEPATH_TRAIN, 'r') as file:\n",
    "    train = json.load(file)\n",
    "\n",
    "with open(FILEPATH_BASE + FILEPATH_DEV, 'r') as file:\n",
    "    dev = json.load(file)\n",
    "\n",
    "with open(FILEPATH_BASE + FILEPATH_TEST, 'r') as file:\n",
    "    test = json.load(file)\n",
    "\n",
    "\n",
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0835b362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statement1': \"'' Someone just came in and shot my daughter and husband , '' Flores ' wife frantically told 911 .\",\n",
       " 'statement2': 'Raul Flores , daughter , 9 , shot dead ; wire calls 911',\n",
       " 'options': ' Entailment or neutral?',\n",
       " 'answer': 'neutral',\n",
       " 'type': 'Type_7',\n",
       " 'statement1_sci_10E': \"'' Someone just came in and shot my daughter and husband , '' Flores ' wife frantically told 9.1100000000E+02 .\",\n",
       " 'statement1_char': \"'' Someone just came in and shot my daughter and husband , '' Flores ' wife frantically told 9 1 1 .\",\n",
       " 'statement1_sci_10E_char': \"'' Someone just came in and shot my daughter and husband , '' Flores ' wife frantically told 9 . 1 1 0 0 0 0 0 0 0 0 E + 0 2 .\",\n",
       " 'statement2_sci_10E': 'Raul Flores , daughter , 9.0000000000E+00 , shot dead ; wire calls 9.0000000000E+0011',\n",
       " 'statement2_char': 'Raul Flores , daughter , 9 , shot dead ; wire calls 9 1 1',\n",
       " 'statement2_sci_10E_char': 'Raul Flores , daughter , 9 . 0 0 0 0 0 0 0 0 0 0 E + 0 0 , shot dead ; wire calls 9 . 0 0 0 0 0 0 0 0 0 0 E + 0 011',\n",
       " 'statement1_mask': \"'' Someone just came in and shot my daughter and husband , '' Flores ' wife frantically told [Num] .\",\n",
       " 'statement2_mask': 'Raul Flores , daughter , [Num] , shot dead ; wire calls [Num]11',\n",
       " 'EQUATE': 'NewsNLI'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b721525",
   "metadata": {},
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d9febf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_same_structure(dicts):\n",
    "    if not dicts:\n",
    "        return True  # An empty list is considered to have the same structure\n",
    "\n",
    "    reference_keys = set(dicts[0].keys())\n",
    "\n",
    "    for d in dicts[1:]:\n",
    "        if set(d.keys()) != reference_keys:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55b0cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(have_same_structure(train))\n",
    "print(have_same_structure(dev))\n",
    "print(have_same_structure(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4abc982d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statement1',\n",
       " 'statement2',\n",
       " 'options',\n",
       " 'answer',\n",
       " 'type',\n",
       " 'statement1_sci_10E',\n",
       " 'statement1_char',\n",
       " 'statement1_sci_10E_char',\n",
       " 'statement2_sci_10E',\n",
       " 'statement2_char',\n",
       " 'statement2_sci_10E_char',\n",
       " 'statement1_mask',\n",
       " 'statement2_mask',\n",
       " 'EQUATE']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c254d8b",
   "metadata": {},
   "source": [
    "Okay so train/dev/test are all lists of dictionaries of the same keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653d1d6",
   "metadata": {},
   "source": [
    "# understand the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "622ad92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(dicts, target_key):\n",
    "    if not dicts:\n",
    "        return True  # An empty list is considered to have the same structure\n",
    "\n",
    "    freq_counts = Counter(item[target_key] for item in dicts)\n",
    "\n",
    "\n",
    "    return freq_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15367e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'StressTest': 4619, 'NewsNLI': 968, 'AWPNLI': 722, 'RTE_Quant': 166})\n",
      "Counter({'StressTest': 970})\n",
      "Counter({'StressTest': 1691})\n"
     ]
    }
   ],
   "source": [
    "print(get_unique_values(train, 'EQUATE'))\n",
    "print(get_unique_values(dev, 'EQUATE'))\n",
    "print(get_unique_values(test, 'EQUATE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1303faab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({' Entailment or contradiction or neutral?': 4619, ' Entailment or neutral?': 1134, ' Entailment or contradiction?': 722})\n",
      "Counter({' Entailment or contradiction or neutral?': 970})\n",
      "Counter({' Entailment or contradiction or neutral?': 1691})\n"
     ]
    }
   ],
   "source": [
    "print(get_unique_values(train, 'options'))\n",
    "print(get_unique_values(dev, 'options'))\n",
    "print(get_unique_values(test, 'options'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b008596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Entailment': 2461, 'neutral': 2112, 'contradiction': 1902})\n",
      "Counter({'Entailment': 324, 'neutral': 323, 'contradiction': 323})\n",
      "Counter({'contradiction': 564, 'neutral': 564, 'Entailment': 563})\n"
     ]
    }
   ],
   "source": [
    "print(get_unique_values(train, 'answer'))\n",
    "print(get_unique_values(dev, 'answer'))\n",
    "print(get_unique_values(test, 'answer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c9dfce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Type_7': 6475})\n",
      "Counter({'Type_7': 970})\n",
      "Counter({'Type_7': 1691})\n"
     ]
    }
   ],
   "source": [
    "print(get_unique_values(train, 'type'))\n",
    "print(get_unique_values(dev, 'type'))\n",
    "print(get_unique_values(test, 'type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fad8bd",
   "metadata": {},
   "source": [
    "Findings: \n",
    "* Only in the `train` set does the data come from different EQUATE subsets. `dev` and `test` all come from Stress dataset. \n",
    "* In `train` set, some of the questions can potentiallly be any of the 3 labels, some questions can only be one of the 2 labels. In `dev` and `test` all questions can have either of the 3 labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251350c",
   "metadata": {},
   "source": [
    "We don't need these 3 fields: `type`,`statement1_mask`, `statement2_mask`.   \n",
    "* Because `type` are all the same (probably referring to the task number in NumGlue since QNLI is task 7 in NumGlue dataset).\n",
    "* `statement1_mask`, `statement2_mask` are not relevant to our task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3875355",
   "metadata": {},
   "source": [
    "Relevant fields are: \n",
    "* (`statement1`, `statement2`) for original notation\n",
    " `options`,\n",
    "* (`statement1_sci_10E`, `statement2_sci_10E`) for scientific notation\n",
    "* (`statement1_char`, `statement2_char`) for character notation\n",
    "* (`statement1_sci_10E_char`, `statement2_sci_10E_char`) for character-scientific notation\n",
    "* `options` indicate the range of possible ansers (only have diff value in `train` set)\n",
    "* `answer` to indicate weather its \"Entailment\", \"Contradiction\", or \"Neutral\"\n",
    "* `EQUATE` to indicate which subset of EQUATE it comes from (only have diff value in `train` set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc006c",
   "metadata": {},
   "source": [
    "# a closer look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d4c8e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>EQUATE</th>\n",
       "      <th>AWPNLI</th>\n",
       "      <th>NewsNLI</th>\n",
       "      <th>RTE_Quant</th>\n",
       "      <th>StressTest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>options</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entailment or contradiction or neutral?</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entailment or contradiction?</th>\n",
       "      <td>722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entailment or neutral?</th>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "EQUATE                                    AWPNLI  NewsNLI  RTE_Quant  \\\n",
       "options                                                                \n",
       " Entailment or contradiction or neutral?       0        0          0   \n",
       " Entailment or contradiction?                722        0          0   \n",
       " Entailment or neutral?                        0      968        166   \n",
       "\n",
       "EQUATE                                    StressTest  \n",
       "options                                               \n",
       " Entailment or contradiction or neutral?        4619  \n",
       " Entailment or contradiction?                      0  \n",
       " Entailment or neutral?                            0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train)\n",
    "\n",
    "cross_tab = pd.crosstab(index=df['options'], columns=df['EQUATE'])\n",
    "\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1f8f4",
   "metadata": {},
   "source": [
    "# is answers evenly distributed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7793503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_percentage(dicts): \n",
    "    answer_counter = get_unique_values(dev, 'answer')\n",
    "        \n",
    "    answer_freq = {key: round(value / len(dev), 2) for key, value in answer_counter.items()}\n",
    "    \n",
    "    return answer_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55541815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0.33, 'Entailment': 0.33, 'contradiction': 0.33}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_percentage(train) # wow it's so balenced, would it differ per source EQUATE? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8964d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0.33, 'Entailment': 0.33, 'contradiction': 0.33}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_percentage(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ec2f892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0.33, 'Entailment': 0.33, 'contradiction': 0.33}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_percentage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b546657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a04a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stress = [if train['EQUATE'] == 'for record in train]\n",
    "answer_dev = get_unique_values(dev, 'answer')\n",
    "answer_test = get_unique_values(test, 'answer')\n",
    "\n",
    "answer_freq_dev = {key: round(value / len(dev), 2) for key, value in answer_dev.items()}\n",
    "answer_freq_test = {key: round(value / len(test), 2) for key, value in answer_test.items()}\n",
    "\n",
    "print(answer_freq_dev)\n",
    "print(answer_freq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43014a",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68e7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
