{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e5535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d52423",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7618da",
   "metadata": {},
   "source": [
    "Embeddings take a tensor of indices of tokens, into a matrix of the embeddings of the tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7a1e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(5, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "embedding_dim = 7\n",
    "\n",
    "emb = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5931dff1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8, 7])\n",
      "tensor([[-1.1659,  1.0582,  0.9662, -0.7761, -0.4046,  0.4042, -0.3711],\n",
      "        [-1.3935,  1.0801,  1.0189,  1.6781,  0.7495,  1.9403, -0.9764],\n",
      "        [ 0.8480, -0.3351, -0.0892,  0.4605, -0.5739, -0.3665,  1.7589],\n",
      "        [-1.6711,  0.8306,  0.9070, -0.0072,  0.1296,  1.2627, -1.4916],\n",
      "        [-0.0062, -1.0555,  2.0760,  0.6944,  0.9913, -0.6511,  1.4319],\n",
      "        [-0.0062, -1.0555,  2.0760,  0.6944,  0.9913, -0.6511,  1.4319],\n",
      "        [-0.0062, -1.0555,  2.0760,  0.6944,  0.9913, -0.6511,  1.4319],\n",
      "        [-0.0062, -1.0555,  2.0760,  0.6944,  0.9913, -0.6511,  1.4319]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0,1,2,3,4,4,4,4])\n",
    "print(x.size())\n",
    "\n",
    "embeddings = emb(x)\n",
    "print(embeddings.size())\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5efb55c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4, 7])\n",
      "tensor([[[-1.1659,  1.0582,  0.9662, -0.7761, -0.4046,  0.4042, -0.3711],\n",
      "         [-1.3935,  1.0801,  1.0189,  1.6781,  0.7495,  1.9403, -0.9764],\n",
      "         [ 0.8480, -0.3351, -0.0892,  0.4605, -0.5739, -0.3665,  1.7589],\n",
      "         [ 0.8480, -0.3351, -0.0892,  0.4605, -0.5739, -0.3665,  1.7589]],\n",
      "\n",
      "        [[ 0.8480, -0.3351, -0.0892,  0.4605, -0.5739, -0.3665,  1.7589],\n",
      "         [-1.6711,  0.8306,  0.9070, -0.0072,  0.1296,  1.2627, -1.4916],\n",
      "         [-0.0062, -1.0555,  2.0760,  0.6944,  0.9913, -0.6511,  1.4319],\n",
      "         [-0.0062, -1.0555,  2.0760,  0.6944,  0.9913, -0.6511,  1.4319]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# what if x is batched input? \n",
    "x_batched = torch.tensor([[0,1,2,2], [2,3,4,4]])\n",
    "print(x_batched.size())\n",
    "\n",
    "embeddings = emb(x_batched)\n",
    "print(embeddings.size())\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec5e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        # self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        # self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c664045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (word_embeddings): Embedding(30, 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(10, 20, 30, 40)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b683c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 3.8494e-01, -5.5391e-01,  9.9834e-01, -1.4209e+00,  1.4911e+00,\n",
      "         -3.7122e-02,  1.8848e+00, -1.0468e-01, -3.7011e-01, -7.3973e-01],\n",
      "        [-6.4030e-01, -1.3119e+00,  1.2074e+00,  1.8469e-01, -2.4438e-01,\n",
      "          2.5076e-02,  2.3591e+00,  2.8905e-01, -1.9081e+00,  8.3450e-02],\n",
      "        [-1.2986e+00, -1.1139e+00, -5.6324e-01,  1.0266e+00,  1.9043e+00,\n",
      "         -2.9037e-01, -3.0238e-01, -1.2839e+00, -2.1847e+00,  8.3514e-01],\n",
      "        [ 2.9673e-01,  9.4009e-01, -1.2846e+00,  1.9970e+00, -7.7268e-01,\n",
      "         -3.9361e-02,  3.3113e-01, -2.2499e-01, -9.4550e-01,  1.6217e-01],\n",
      "        [-7.7959e-01, -5.4716e-01, -2.3300e-01,  2.0358e+00, -9.7984e-01,\n",
      "          6.7819e-01,  6.1051e-01,  8.7500e-01,  5.6072e-01, -6.7303e-01],\n",
      "        [ 5.4724e-01, -1.9696e-01, -1.0326e-01, -3.1680e-01,  3.1085e-01,\n",
      "          1.2024e+00, -3.7980e-01,  2.7570e-01, -1.6197e+00, -1.1814e-01],\n",
      "        [-4.4478e-01,  8.1144e-02, -1.0417e-01, -5.5334e-01,  1.4114e-01,\n",
      "          2.2855e-01, -1.0454e+00,  7.2944e-01, -2.1803e-01, -5.6104e-01],\n",
      "        [ 1.4481e+00, -1.6668e-01,  4.9739e-01,  2.5887e-01,  8.0317e-01,\n",
      "          2.8545e-01,  7.8347e-01, -9.3861e-02, -2.4941e-01, -1.1320e+00],\n",
      "        [-2.2416e-01,  5.6345e-01, -1.5955e+00, -3.4826e-01, -7.6765e-01,\n",
      "          5.9027e-01,  1.1390e-01,  5.6615e-01,  9.5018e-01, -7.7620e-01],\n",
      "        [ 1.5559e-01,  6.0090e-01, -1.8622e+00, -7.9738e-01,  1.2066e+00,\n",
      "          4.8293e-01, -1.1490e+00,  6.7129e-01, -1.2096e+00,  6.4699e-01],\n",
      "        [-1.8095e-01,  8.8351e-01,  2.2206e-01, -4.5009e-02,  8.2887e-01,\n",
      "          4.8384e-01,  8.1880e-01,  3.9237e-01,  8.0493e-01, -2.2542e-01],\n",
      "        [-1.9825e-01, -1.1848e+00, -1.6216e+00, -5.0826e-01, -1.1372e-01,\n",
      "          1.0672e+00, -5.8301e-01, -1.6402e+00, -1.7587e-01, -7.0327e-01],\n",
      "        [-4.7444e-01, -1.5023e-01,  9.9742e-01,  3.8819e-01,  7.0010e-01,\n",
      "          1.2281e+00, -6.4075e-01, -6.5846e-01,  1.3898e-02,  5.0353e-01],\n",
      "        [-8.8028e-01,  2.0367e-01, -2.0200e-01, -1.5437e+00,  1.1479e+00,\n",
      "          4.0845e-02,  5.5609e-01, -1.1843e+00,  1.3491e+00,  1.6738e+00],\n",
      "        [-1.3158e+00, -1.1342e+00,  6.6527e-01, -8.0547e-01,  5.6941e-01,\n",
      "         -1.8885e+00, -2.1948e-01, -6.4857e-01,  1.0090e+00, -7.9698e-01],\n",
      "        [ 1.4857e-01,  1.3192e+00, -8.9237e-01, -9.3655e-02, -7.7574e-01,\n",
      "         -3.2050e-01, -4.4066e-01,  1.1113e+00, -3.3058e-01,  1.4991e-01],\n",
      "        [-7.0883e-01, -1.6215e+00, -9.5734e-01,  7.2262e-01, -1.0396e+00,\n",
      "          8.1379e-01,  6.6447e-01, -4.9889e-01,  8.3833e-01,  1.3521e-01],\n",
      "        [ 1.5833e+00,  4.0192e-01, -2.6168e-01,  6.1453e-01,  1.4788e-01,\n",
      "          1.3528e+00,  4.8712e-01,  8.0610e-01, -2.6987e-03,  1.3180e+00],\n",
      "        [ 1.0576e-01,  2.1731e-01,  4.0108e-01,  6.9088e-01, -2.4482e-01,\n",
      "          1.4787e-01, -1.2560e+00,  9.0560e-01,  1.6560e+00,  4.7541e-01],\n",
      "        [-8.7187e-01,  1.1559e+00, -2.7999e-01, -8.2493e-02,  7.9904e-01,\n",
      "         -8.7959e-01,  3.6427e-01, -4.4371e-01, -5.9259e-01,  3.0076e-01],\n",
      "        [-2.3566e-01, -1.1898e+00,  4.7620e-01, -1.1442e+00, -4.8870e-01,\n",
      "          2.0628e+00,  8.4340e-01, -4.4669e-01, -3.1349e-01,  9.2741e-01],\n",
      "        [ 5.9641e-02, -3.5277e-02,  1.8447e+00, -2.9315e-01, -3.9975e-01,\n",
      "         -1.4458e+00,  7.0191e-01,  1.1423e+00,  2.6796e+00, -1.3769e+00],\n",
      "        [-8.8199e-01, -1.5849e+00, -5.5343e-01, -3.7947e-01,  5.0887e-01,\n",
      "          1.2256e+00, -2.3135e-01,  1.0775e+00, -1.0232e+00, -1.8390e-01],\n",
      "        [ 2.5734e-01, -7.3543e-01,  1.8542e+00,  3.5635e-01,  3.5592e-01,\n",
      "         -8.2200e-02,  4.2715e-01, -3.0523e-01,  1.4532e-01,  4.2985e-01],\n",
      "        [-1.2111e+00, -1.6540e-01, -7.9248e-01,  1.0774e+00, -1.2763e+00,\n",
      "         -6.5871e-01,  4.9718e-01, -9.9242e-01,  1.5624e+00,  4.9163e-01],\n",
      "        [ 4.8840e-03, -3.6859e-02, -1.0946e+00, -1.0881e+00, -2.1836e+00,\n",
      "         -3.4320e-01,  1.6267e+00,  1.0178e+00,  1.0786e+00,  1.7011e-01],\n",
      "        [ 7.5530e-01, -6.1030e-02,  7.3958e-01,  4.0993e-01, -1.2748e-01,\n",
      "         -3.0982e-01, -1.0916e+00, -3.3344e-01, -3.4758e-01,  1.5230e+00],\n",
      "        [-2.3321e-01, -1.6965e-01, -6.7762e-02, -3.8933e-01, -7.1945e-01,\n",
      "         -7.2144e-01, -5.8781e-01, -7.2856e-01,  1.2659e+00,  9.3352e-01],\n",
      "        [-1.9987e-01,  2.4478e+00,  1.7249e-01, -5.2254e-01, -5.8837e-02,\n",
      "         -1.0385e+00,  1.7531e+00, -5.5916e-01,  1.2057e+00, -2.7682e+00],\n",
      "        [ 2.1456e-01,  4.1370e-01, -4.8241e-01, -7.3035e-01,  7.4101e-01,\n",
      "         -1.4264e+00,  2.0280e-01, -3.5086e-01,  2.4114e-01,  1.3533e+00]],\n",
      "       requires_grad=True)\n",
      "torch.Size([30, 10])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters(): \n",
    "    print(param)\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b4eb4",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d6774",
   "metadata": {},
   "source": [
    "## Example of target with class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e4c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d4711e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e401ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408c24fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4212, -0.4190,  0.1881,  0.6210,  0.1523],\n",
       "        [ 1.2478, -2.2200, -0.7616,  1.1415,  0.3109],\n",
       "        [ 0.0583,  0.8081,  0.4962,  0.6873,  0.8748]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8ad74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc577b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc14f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3fe52cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0394,  0.0395,  0.0725, -0.2215,  0.0700],\n",
       "        [ 0.1357,  0.0042, -0.3151,  0.1220,  0.0532],\n",
       "        [ 0.0379,  0.0801,  0.0587,  0.0710, -0.2477]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd5237",
   "metadata": {},
   "source": [
    "## Example of target with class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a36d9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbc3dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41bc855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e4cd74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1829,  0.2004,  0.8537, -0.0622,  0.9630],\n",
       "        [-0.7863, -1.9025, -0.9376,  0.8261,  1.0012],\n",
       "        [ 1.8848,  1.7796, -1.5515,  0.5112,  0.0946]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff9e8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3725f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0520, 0.1592, 0.1407, 0.3805, 0.2676],\n",
       "        [0.3378, 0.0565, 0.3831, 0.1195, 0.1031],\n",
       "        [0.0207, 0.1292, 0.0734, 0.0547, 0.7221]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56679f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e37db3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0307, -0.0042,  0.0471, -0.0892,  0.0156],\n",
       "        [-0.0873, -0.0105, -0.1060,  0.0871,  0.1168],\n",
       "        [ 0.1348,  0.0845, -0.0199,  0.0176, -0.2171]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053069d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01163dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48064/250565712.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845868/work/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  output.grad\n"
     ]
    }
   ],
   "source": [
    "output.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393a121",
   "metadata": {},
   "source": [
    "# tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e6e1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your 2D tensor\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Get the last row\n",
    "last_row = tensor_2d[-1]\n",
    "\n",
    "print(last_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d5e982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor_2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a91c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = torch.zeros(256)\n",
    "\n",
    "h_0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f0fc8d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_0 = h_0.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "h_0.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f784b411",
   "metadata": {},
   "source": [
    "# extract the last non-zero along an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b11bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_tensor(non_zeros, zeros): \n",
    "    t = torch.arange(non_zeros)\n",
    "\n",
    "    t0 = torch.zeros(zeros, dtype=t.dtype)\n",
    "\n",
    "    result_tensor = torch.cat((t, t0)).view(8,4)\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6108d3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = get_sample_tensor(20, 12)\n",
    "t2 = get_sample_tensor(32, 0)\n",
    "t3 = get_sample_tensor(16, 16)\n",
    "\n",
    "t1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aae962f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output = torch.stack([t1, t2, t3], dim=0)\n",
    "rnn_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f23c84b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [ 0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0]],\n",
       "\n",
       "        [[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]],\n",
       "\n",
       "        [[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [ 0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5d8458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sequence lengths (L)\n",
    "sequence_lengths = [5, 8, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "562374f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True, False, False, False, False]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mask to indicate valid positions\n",
    "mask = torch.arange(rnn_output.size(1)).unsqueeze(0) < torch.tensor(sequence_lengths).unsqueeze(1)\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ec60ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 7, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the last non-zero position along the sequence dimension\n",
    "last_non_zero_positions = torch.max(mask * torch.arange(rnn_output.size(1)), dim=1).values\n",
    "last_non_zero_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f735628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 0, 0, 0],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "        [0, 1, 2, 3, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask * torch.arange(rnn_output.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a3bdb18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Extract the last non-zero tensor along the sequence dimension\n",
    "final_outputs = rnn_output[torch.arange(rnn_output.size(0)), last_non_zero_positions]\n",
    "\n",
    "print(final_outputs.shape)  # Size: (N, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bde39b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp \n",
    "torch.stack([torch.tensor(1),torch.tensor(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e21037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f18dfb",
   "metadata": {},
   "source": [
    "## broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f38183",
   "metadata": {},
   "source": [
    "In the case of comparing a tensor of size (1, 8) and a tensor of size (3, 1), the result will be a tensor of size (3, 8). This is again due to broadcasting rules.\n",
    "\n",
    "When performing element-wise operations (such as comparison) between two tensors, PyTorch compares their dimensions element-wise, **starting from the rightmost dimension**. Broadcasting allows the tensors to be compatible for element-wise operations when:\n",
    "\n",
    "1. The size of the dimensions matches.\n",
    "2. One of the sizes is 1.  \n",
    "\n",
    "Let's look at the example:\n",
    "\n",
    "Tensor A: (1, 8)\n",
    "Tensor B: (3, 1)  \n",
    "\n",
    "In this case, PyTorch will broadcast the smaller tensor (Tensor B) along its singleton dimension to match the size of the corresponding dimension in the larger tensor (Tensor A). Broadcasting will stretch Tensor B to have the same size as Tensor A along the second dimension. As a result, you get a tensor of size (3, 8) when performing element-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27f7d897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True, False, False, False, False]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.arange(rnn_output.size(1)).unsqueeze(0) < torch.tensor(sequence_lengths).unsqueeze(1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "373d1973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "torch.Size([8])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "# temp\n",
    "print(torch.arange(rnn_output.size(1)))\n",
    "print(torch.arange(rnn_output.size(1)).size())\n",
    "print(torch.arange(rnn_output.size(1)).unsqueeze(0))\n",
    "print(torch.arange(rnn_output.size(1)).unsqueeze(0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fdf2831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 8, 4])\n",
      "torch.Size([3])\n",
      "tensor([[5],\n",
      "        [8],\n",
      "        [4]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# temp\n",
    "print(torch.tensor(sequence_lengths))\n",
    "print(torch.tensor(sequence_lengths).size())\n",
    "print(torch.tensor(sequence_lengths).unsqueeze(1))\n",
    "print(torch.tensor(sequence_lengths).unsqueeze(1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34caf71",
   "metadata": {},
   "source": [
    "# Extract specific element along axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5aed951f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of size (3, 10)\n",
    "tensor = torch.arange(30).view(3, 10)\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7300c5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths = torch.tensor([2,4,8])\n",
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43ecf43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = seq_lengths - 1\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea2e2d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 13, 27])\n"
     ]
    }
   ],
   "source": [
    "# Use fancy indexing to extract elements from each row\n",
    "result = tensor[range(tensor.size(0)), indices]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8be166f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 13, 27])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tensor[[0,1,2], indices]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69047d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.LongTensor{[3, 1]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# indices = (seq_lengths - 1).view(-1, 1).expand(len(seq_lengths), out_unpacked.size(2)).unsqueeze(0)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m indices \u001b[38;5;241m=\u001b[39m (seq_lengths \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mlen\u001b[39m(seq_lengths))\n\u001b[1;32m      3\u001b[0m indices\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.LongTensor{[3, 1]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "# indices = (seq_lengths - 1).view(-1, 1).expand(len(seq_lengths), out_unpacked.size(2)).unsqueeze(0)\n",
    "indices = (seq_lengths - 1).view(-1, 1).expand(len(seq_lengths))\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1203b",
   "metadata": {},
   "source": [
    "# pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_lengths: tensor([43,  35,  30, 138])\n",
    "# sorted_indices=tensor([3, 0, 1, 2]), unsorted_indices=tensor([1, 2, 3, 0])\n",
    "\n",
    "# [138, 43, 35, 30]\n",
    "\n",
    "# for the first 30 cells, all 4 tensor have it\n",
    "# continue till the 35th cell, the first 3 tensors have it\n",
    "# continue till the 43th cell, the first 2 tensors have it\n",
    "# till the end, only the first 1 tensor have it\n",
    "\n",
    "batch_sizes = [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "        4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d882cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "        4, 4, 4, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "        4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "        4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fddada",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
    "        4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231993bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([138, 43, 35, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3abbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa989c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8)[None, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([ 0.2054,  0.0020,  0.0486,  0.0508,  0.1717,  0.4226,  0.0641,  0.2693,\n",
    "        -0.1672,  0.5834,  0.1972,  0.0074,  0.2665, -0.1019, -0.2332, -0.2746,\n",
    "         0.2326,  0.2747,  0.1856,  0.2407,  0.4252,  0.2461,  0.2270,  0.4674,\n",
    "        -0.3185, -0.3030, -0.1261,  0.0362, -0.0045,  0.0117,  0.1414,  0.1806,\n",
    "         0.3911,  0.4545, -0.2965,  0.0517,  0.1228,  0.4499,  0.4384,  0.0195,\n",
    "         0.1236, -0.1288,  0.0365,  0.0000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985a144",
   "metadata": {},
   "source": [
    "# sort a counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_str1 = \"\"\"\n",
    "(tensor([ 113, 1376,  519, 1320,   10,    7, 1811, 1338, 1148,    7, 4311,    3,\n",
    "         113, 4312,   24, 1676, 6154,  821, 2084,   25,    0, 6155, 4312,    3,\n",
    "        1148,    3,  112,    3, 1811,  951,  803, 3720, 1123, 2084,    0,    6,\n",
    "           8,    2,    9]), tensor(1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_str2 = \"\"\"\n",
    "(tensor([ 113, 1376,  519, 1320,   10,    7, 1811, 1338, 1148,    7, 4311,    3,\n",
    "         113, 4312,   24, 1676, 6154,  821, 2084,   25,    0, 6155, 4312,    3,\n",
    "        1148,    3,  112,    3, 1811,  951,  803, 3720, 1123, 2084,    0,    6,\n",
    "           8,    2,    9]), tensor(1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd74fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tensor_str1 == tensor_str2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec51f0",
   "metadata": {},
   "source": [
    "# dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f427bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 6, 3, 8],\n",
       "        [5, 2, 7, 4]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,6,3,8], [5,2,7,4]])\n",
    "print(t.size())\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9f50e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [6],\n",
       "         [3],\n",
       "         [8]],\n",
       "\n",
       "        [[5],\n",
       "         [2],\n",
       "         [7],\n",
       "         [4]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.unsqueeze(-1)\n",
    "print(t.size())\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af3b6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1],\n",
       "         [6, 6, 6],\n",
       "         [3, 3, 3],\n",
       "         [8, 8, 8]],\n",
       "\n",
       "        [[5, 5, 5],\n",
       "         [2, 2, 2],\n",
       "         [7, 7, 7],\n",
       "         [4, 4, 4]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t.expand(-1, -1, 3)\n",
    "print(t.size())\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb3bc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.argmax(t, dim=2)\n",
    "print(s.size())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97624c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 //3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2779281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(x):\n",
    "    \"\"\"\n",
    "    This function accepts a parameter x and asserts that it is greater than 0.\n",
    "    \"\"\"\n",
    "    assert x > 0, \"x must be greater than 0\"\n",
    "    # Rest of the function code here\n",
    "\n",
    "# Example usage:\n",
    "my_function(5)  # This will pass the assertion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "359a297c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "x must be greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This will raise an AssertionError because -1 is not greater than 0\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m my_function(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[74], line 5\u001b[0m, in \u001b[0;36mmy_function\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmy_function\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    This function accepts a parameter x and asserts that it is greater than 0.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx must be greater than 0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: x must be greater than 0"
     ]
    }
   ],
   "source": [
    "# This will raise an AssertionError because -1 is not greater than 0\n",
    "my_function(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9444ddc",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
